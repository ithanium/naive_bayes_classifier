The data to be used in the laboratory is available in the following zip file "silence_speech.zip" available at the bottom of this text block.

The zip file contains 100 audio files, each of which has a duration of 300ms, extracted from telephone conversations. For each of those 100 audio files (in .wav format), the zip file contains one corresponding file in the same .dat format as the previous exercise.

The files were extracted from segments of speech and silence, and are named accordingly. The zip file contains 50 files for the "Silence" class and 50 files for the "Speech" class.

The goals of the exercise are as follows:

    extract features summarizing each audio file
    use those features to build a classifier able to automatically discriminate between the "Silence" and "Speech" classes
    assess the performance of the classification approach

In order to achieve those goals, the tasks to be performed are as follows:

    For each of the 100 signals, compute and store in a text file the following three feature values (that we will denote by 'E', 'M', and 'Z'):

        'E' - Logarithm of the average value of the short-term energy signal
        'M' - Logarithm of the average value of the short-term magnitude signal
        'Z' - Average value of the Zero Crossing Rate signal

    Produce three scatter plots, showing all the audio signals, using the following three combinations of features:
        'E' versus 'M'
        'E' versus 'Z'
        'M' versus 'Z'

    Repeat the following steps in a cross-validation fashion, using K-fold validation with K=10:
        Split the data set into training and test sets keeping the training set balanced, namely with half "Speech" and half "Silence" audio samples
        Train Gaussian discriminant functions for decisions "Speech" and "Silence"
        Compute the average loss over the test set

    Compute the average loss of the K-fold validation procedure
